Este reposit√≥rio cont√©m um projeto abrangendo a implementa√ß√£o de um **Algoritmo Gen√©tico** para o Problema do Caixeiro Viajante (TSP) e uma an√°lise de **Modelagem Vetorial de Linguagem Natural (NLP)** comparando t√©cnicas cl√°ssicas e de Deep Learning.
> Trabalho realizado para a disciplina: T√≥picos em IA, no curso de Intelig√™ncia Artifical Aplicada da UFPR

---

## üöÄ Estrutura do Projeto

O projeto est√° dividido em duas partes principais:

### 1. Algoritmo Gen√©tico (TSP - Traveling Salesperson Problem)

O objetivo √© encontrar a menor rota que passe por 100 cidades geradas aleatoriamente em um mapa 100x100, retornando ao ponto de origem.

**Caracter√≠sticas da Implementa√ß√£o:**

* **Gera√ß√£o de Cidades:** Coordenadas (x, y) √∫nicas geradas aleatoriamente.
* **Popula√ß√£o Inicial:** Criada atrav√©s de permuta√ß√µes aleat√≥rias dos √≠ndices das cidades.
* **Fun√ß√£o de Fitness:** Baseada na dist√¢ncia euclidiana total da rota.
* **Operadores Gen√©ticos:**
* **Cruzamento (Crossover):** T√©cnica **OX (Ordered Crossover)**, que preserva a ordem relativa das cidades sem duplicatas.
* **Muta√ß√£o:** T√©cnica **Swap Mutation**, trocando a posi√ß√£o de duas cidades na rota.


* **Par√¢metros Utilizados:**
* Gera√ß√µes: 1000.
* Tamanho da Popula√ß√£o: 100.
* Taxa de Cruzamento: 90%.
* Taxa de Muta√ß√£o: 1%.



**Resultados obtidos:**

* Melhora significativa na dist√¢ncia total (redu√ß√£o de aproximadamente **69.71%** em rela√ß√£o √† melhor solu√ß√£o inicial).
* Gr√°ficos gerados de converg√™ncia da dist√¢ncia e visualiza√ß√£o da rota final no mapa.

---

### 2. Modelagem Vetorial e NLP (Processamento de Linguagem Natural)

Uma compara√ß√£o entre representa√ß√µes estat√≠sticas e sem√¢nticas de texto, utilizando proje√ß√£o 2D para an√°lise de agrupamento.

**Modelos Comparados:**

1. **TF-IDF (Term Frequency-Inverse Document Frequency):** Modelo estat√≠stico cl√°ssico que valoriza palavras raras e penaliza as muito frequentes no corpus.
2. **Sentence-BERT (S-BERT):** Utiliza√ß√£o do modelo pr√©-treinado `paraphrase-multilingual-MiniLM-L12-v2` para extrair *embeddings* sem√¢nticos que capturam o contexto e significado das frases em m√∫ltiplos idiomas.

**Visualiza√ß√£o:**

* Aplica√ß√£o de **PCA (Principal Component Analysis)** para reduzir a dimensionalidade dos vetores para 2D.
* Gera√ß√£o de gr√°ficos de dispers√£o para observar como os diferentes modelos agrupam senten√ßas similares.

---

## üõ†Ô∏è Tecnologias e Bibliotecas Utilizadas

O projeto foi desenvolvido em Python, utilizando as seguintes bibliotecas:

* **NumPy:** Manipula√ß√£o de matrizes e c√°lculos matem√°ticos.
* **Matplotlib / Seaborn:** Gera√ß√£o de gr√°ficos e visualiza√ß√£o de dados.
* **Scikit-learn:** Implementa√ß√£o de TF-IDF e PCA.
* **Sentence-Transformers (Hugging Face):** Implementa√ß√£o do modelo BERT.
* **Pandas:** Estrutura√ß√£o de dados para visualiza√ß√£o.

---

## üìã Como Executar

### Pr√©-requisitos

Certifique-se de ter o Python instalado (recomendado 3.10+). Instale as depend√™ncias necess√°rias:

```bash
pip install numpy matplotlib pandas seaborn scikit-learn sentence-transformers

```

### Execu√ß√£o

1. **Notebook:** Abra o arquivo `Trabalho_Final_IAA015.ipynb` no Google Colab ou Jupyter Notebook e execute as c√©lulas sequencialmente.
2. **Script Python:** Execute o arquivo `trabalho_final_iaa015.py` diretamente no terminal:

```bash
python trabalho_final_iaa015.py

```

---

## üìä Principais Conclus√µes

* O **Algoritmo Gen√©tico** demonstrou ser eficiente para o TSP, apresentando uma curva de aprendizado consistente ao longo das gera√ß√µes.
* Na an√°lise de **NLP**, o modelo **S-BERT** apresentou agrupamentos mais intuitivos e coerentes em compara√ß√£o ao TF-IDF, uma vez que considera a sem√¢ntica das frases e n√£o apenas a frequ√™ncia de termos isolados.

---
